{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Case Study: Using AI to Improve Demand Forecasting in Retail"
      ],
      "metadata": {
        "id": "RpMQyRm9ZQUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "In this case study, Master's students in Applied Economics will analyze how AI techniques can be applied to enhance demand forecasting for a retail company. Demand forecasting is crucial for optimizing inventory levels, reducing waste and improving profitability. The students will use machine learning models to forecast demand based on stores, historical sales, temperature in the region, fuel price and economic indicators.\n",
        "\n",
        "**Problem Identification**\n",
        "\n",
        "The retail company is facing challenges in accurately predicting product demand, leading to overstocking of some items and understocking of others. This results in:\n",
        "\n",
        "- High inventory costs due to overstocking.\n",
        "- Lost sales due to understocking, as popular products are often out of stock.\n",
        "- Increased waste from unsold perishables.\n",
        "The goal is to develop a more accurate demand forecasting model using AI techniques to:\n",
        "\n",
        "- Reduce inventory costs.\n",
        "- Maximize sales potential.\n",
        "- Minimize waste.\n",
        "\n",
        "**Problem Identification Techniques**\n",
        "\n",
        "To identify the exact problem, the following techniques can be used:\n",
        "\n",
        "- SWOT Analysis: Assess the company’s current forecasting strengths and weaknesses, the opportunities in improving forecasting accuracy, and threats from competitors who are adopting AI.\n",
        "\n",
        "- Root Cause Analysis (Fishbone Diagram): Investigate different factors affecting demand forecasting (pricing, promotions, seasonality, customer behavior, economic factors, etc.) and identify which are most challenging to predict.\n",
        "\n",
        "- Time-Series Analysis: Analyze historical sales data to observe patterns, trends, seasonality, and irregularities."
      ],
      "metadata": {
        "id": "SrTXH_zUYpac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "Q7Zfet9SlTGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading datasets into Google Colab Drive.**\n",
        "- Dataset name.: Walmart Condensed Sales Data\n",
        "- Source.: https://www.kaggle.com/datasets/souravprakashai/walmart-condensed-sales-data"
      ],
      "metadata": {
        "id": "H3-M1G4SSBTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIvctcxMR1E0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Libraries**"
      ],
      "metadata": {
        "id": "y91OqRRhzTN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1hGII90izPVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**"
      ],
      "metadata": {
        "id": "cUzisENIDpbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "df = pd.read_csv('/content/walmart.csv')  # Make sure the path matches your file's name\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "xKu7cgyiDvbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the data:**\n",
        "\n",
        "- Missing Data Handling: Use interpolation or imputation techniques to fill gaps in data.\n",
        "- Feature Engineering: Create new features such as “days to promotion” or “lagged sales” to better capture demand patterns.\n",
        "- Normalization: Standardize the data to make it compatible with machine learning models."
      ],
      "metadata": {
        "id": "4snD0rSFSTKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing missing values.\n",
        "df = df.dropna()\n",
        "\n",
        "# Feature engineering: create a new feature that represents the lagged sales (sales from the previous week)\n",
        "df['Lagged_Sales'] = df['Weekly_Sales'].shift(1).bfill()\n",
        "\n",
        "# Convert 'Date' to datetime and extract numerical features\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "\n",
        "# Extract day, month, and year as separate numerical features\n",
        "df['Day'] = df['Date'].dt.day\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Normalize the numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[['Fuel_Price', 'CPI', 'Lagged_Sales', 'Temperature', 'Unemployment']] = scaler.fit_transform(df[['Fuel_Price', 'CPI', 'Lagged_Sales', 'Temperature', 'Unemployment']])\n",
        "\n",
        "# Include the new features\n",
        "X = df[['Store', 'Day', 'Month','Fuel_Price', 'CPI', 'Lagged_Sales', 'Temperature', 'Unemployment', 'Holiday_Flag']]  # Features\n",
        "\n",
        "# Identify the target\n",
        "y = df['Weekly_Sales']  # Target (Weekly_Sales)\n",
        "\n",
        "print(df.head())  # Check the preprocessed data"
      ],
      "metadata": {
        "id": "OdQLueLynLhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the dataset into Train and Test sets**"
      ],
      "metadata": {
        "id": "Led4mGl0EH5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split index based on the date, for example, 80% of the data will be training data\n",
        "train_size = int(0.8 * len(df))\n",
        "\n",
        "# Split data into training and test sets (train on first 80%, test on last 20%)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Split the dataset into training and testing sets (train and test sets defined randomly)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hrECygl8EcAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split index based on the date, for example, 80% of the data will be training data\n",
        "train_size = int(0.8 * len(df))\n",
        "\n",
        "# Split data into training and test sets (train on first 80%, test on last 20%)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "print(\"Split based on the first 80% of the data:\")\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
        "print(\"\\nFirst few rows of X_train:\")\n",
        "print(X_train.head())\n",
        "print(\"\\nFirst few rows of y_train:\")\n",
        "print(y_train.head())\n",
        "\n",
        "# Split the dataset into training and testing sets (train and test sets defined randomly)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nRandom split (80% training, 20% testing):\")\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
        "print(\"\\nFirst few rows of X_train after random split:\")\n",
        "print(X_train.head())\n",
        "print(\"\\nFirst few rows of y_train after random split:\")\n",
        "print(y_train.head())"
      ],
      "metadata": {
        "id": "L04xQT9hNemb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "k9f2GoHSyD0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply different techniques to build the demand forecasting model:**\n",
        "\n",
        "- Linear Regression (Baseline Model): This simple model will be used as a baseline to measure the improvement made by more advanced techniques. It predicts demand based on historical sales and price.\n",
        "\n",
        "- Ridge Regression: A version of linear regression that adds a penalty to prevent the model from becoming too complex, making it more robust and better at handling real-world data.\n",
        "\n",
        "- Random Forest Regressor: A robust tree-based model that handles non-linear relationships and can capture the importance of different features (e.g., promotions, seasonality).\n",
        "\n",
        "- XGBRegressor: It is a method to predict continuous values by combining lots of decision trees in a way that gets progressively more accurate over time. It is widely used in fields like finance, marketing, and economics where accurate numerical predictions are important."
      ],
      "metadata": {
        "id": "9m0yQXGOsKDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "X4BusiFLz309"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Linear Regressor\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "# Make predictions\n",
        "linear_pred = linear_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ltf3z_NDsfty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Linear Regressor\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Print the model's coefficients and intercept\n",
        "print(\"Linear Regression Model Coefficients:\")\n",
        "print(linear_model.coef_)\n",
        "print(\"\\nIntercept:\")\n",
        "print(linear_model.intercept_)\n",
        "\n",
        "# Make predictions\n",
        "linear_pred = linear_model.predict(X_test)\n",
        "\n",
        "# Print the first few predictions alongside the actual values\n",
        "print(\"\\nFirst 5 Predictions vs Actual Values:\")\n",
        "for pred, actual in zip(linear_pred[:5], y_test[:5]):\n",
        "    print(f\"Predicted: {pred:.2f}, Actual: {actual}\")\n"
      ],
      "metadata": {
        "id": "SUzP3MPvN5Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression**"
      ],
      "metadata": {
        "id": "9DUHZxGwJIkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization: Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "# Make predictions\n",
        "ridge_pred = ridge_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "2FIqX0FNKtBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization: Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Print the model's coefficients and intercept\n",
        "print(\"Ridge Regression Model Coefficients:\")\n",
        "print(ridge_model.coef_)\n",
        "print(\"\\nIntercept:\")\n",
        "print(ridge_model.intercept_)\n",
        "\n",
        "# Make predictions\n",
        "ridge_pred = ridge_model.predict(X_test)\n",
        "\n",
        "# Print the first few predictions alongside the actual values\n",
        "print(\"\\nFirst 5 Predictions vs Actual Values:\")\n",
        "for pred, actual in zip(ridge_pred[:5], y_test[:5]):\n",
        "    print(f\"Predicted: {pred:.2f}, Actual: {actual}\")"
      ],
      "metadata": {
        "id": "UxfTSVLBOF35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regressor**"
      ],
      "metadata": {
        "id": "eps7gyO_y8E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "# Make predictions\n",
        "random_forest_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "marqu9QZ1HLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances from Random Forest Regressor:\")\n",
        "print(model.feature_importances_)\n",
        "\n",
        "# Make predictions\n",
        "random_forest_pred = model.predict(X_test)\n",
        "\n",
        "# Print the first few predictions alongside the actual values\n",
        "print(\"\\nFirst 5 Predictions vs Actual Values:\")\n",
        "for pred, actual in zip(random_forest_pred[:5], y_test[:5]):\n",
        "    print(f\"Predicted: {pred:.2f}, Actual: {actual}\")"
      ],
      "metadata": {
        "id": "TQDeRgpoOLqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Regressor**"
      ],
      "metadata": {
        "id": "5h7lUAC7KGQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr = XGBRegressor(n_estimators = 200)\n",
        "xgbr.fit(X_train, y_train)\n",
        "# Make predictions\n",
        "xgb_pred = xgbr.predict(X_test)"
      ],
      "metadata": {
        "id": "S6J0DAsauQhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply XGBoost Regressor\n",
        "xgbr = XGBRegressor(n_estimators=200)\n",
        "xgbr.fit(X_train, y_train)\n",
        "\n",
        "# Print the feature importances\n",
        "print(\"Feature Importances from XGBoost Regressor:\")\n",
        "print(xgbr.feature_importances_)\n",
        "\n",
        "# Make predictions\n",
        "xgb_pred = xgbr.predict(X_test)\n",
        "\n",
        "# Print the first few predictions alongside the actual values\n",
        "print(\"\\nFirst 5 Predictions vs Actual Values:\")\n",
        "for pred, actual in zip(xgb_pred[:5], y_test[:5]):\n",
        "    print(f\"Predicted: {pred:.2f}, Actual: {actual}\")"
      ],
      "metadata": {
        "id": "twFe39ScOQCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the models"
      ],
      "metadata": {
        "id": "YejcO4IsLMS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model with Standard Indicators:**\n",
        "\n",
        "- Mean Absolute Error (MAE): Measures the average absolute difference between actual and predicted sales.\n",
        "- Mean Squared Error (MSE): Measures the average squared difference between the predicted values and the actual values.\n",
        "- r2_score: Measures the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model."
      ],
      "metadata": {
        "id": "I69_7muBw5CQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "tG_-vCjHKfLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, linear_pred)\n",
        "mse = mean_squared_error(y_test, linear_pred)\n",
        "r2 = r2_score(y_test, linear_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")"
      ],
      "metadata": {
        "id": "fPrAVRl6xpa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression**"
      ],
      "metadata": {
        "id": "pG22oy00MAlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, ridge_pred)\n",
        "mse = mean_squared_error(y_test, ridge_pred)\n",
        "r2 = r2_score(y_test, ridge_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")"
      ],
      "metadata": {
        "id": "cnCd3WLUI7tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "Yby1wDxqyXN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, random_forest_pred)\n",
        "mse = mean_squared_error(y_test, random_forest_pred)\n",
        "r2 = r2_score(y_test, random_forest_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")"
      ],
      "metadata": {
        "id": "jpyT3pPFIWx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Regressor**"
      ],
      "metadata": {
        "id": "0I2hVYyvMY69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, xgb_pred)\n",
        "mse = mean_squared_error(y_test, xgb_pred)\n",
        "r2 = r2_score(y_test, xgb_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")"
      ],
      "metadata": {
        "id": "nlOSCAitKRXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize how close the best model's predicted sales are to the real sales for the first 100 rows.**"
      ],
      "metadata": {
        "id": "AQp5GjS0R7HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame and display the first 100 rows."
      ],
      "metadata": {
        "id": "hjU3xVB0UM-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to compare actual and predicted sales\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Index': X_test[:100].index.sort_values(),\n",
        "    'Actual Sales': y_test[:100],\n",
        "    'Predicted Sales': xgb_pred[:100]\n",
        "})\n",
        "# Format the values to two decimal places for better readability\n",
        "formatted_df = comparison_df.style.format({'Actual Sales': '{:,.2f}', 'Predicted Sales': '{:,.2f}'})\n",
        "\n",
        "# Display the formatted table\n",
        "formatted_df"
      ],
      "metadata": {
        "id": "guB9YGhTTG6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting both actual and predicted sales on a line chart. Blue represents actual sales, and red (dashed) represents the predicted sales."
      ],
      "metadata": {
        "id": "ypTa6ZqXT9W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the index for easy plotting\n",
        "comparison_df.set_index('Index', inplace=True)\n",
        "\n",
        "# Plot the actual and predicted sales\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(comparison_df.index, comparison_df['Actual Sales'], label='Actual Sales', color='blue', linewidth=2)\n",
        "plt.plot(comparison_df.index, comparison_df['Predicted Sales'], label='Predicted Sales', color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Actual vs Predicted Sales', fontsize=16)\n",
        "plt.xlabel('Index', fontsize=12)\n",
        "plt.ylabel('Sales', fontsize=12)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hamdfYEdyiWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting"
      ],
      "metadata": {
        "id": "qjlOpQlwOgDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forecast sales for each store over the next 4 weeks and updates the sales predictions week by week, using the predicted sales from the previous week as input for the next. The goal is to help store managers see what sales might look like in the future."
      ],
      "metadata": {
        "id": "W6Qwd6S-y7Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the last week's records for each store from the Walmart dataset."
      ],
      "metadata": {
        "id": "mKcjXeEDxF2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'Date' column is in datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Identify the last week (i.e., latest date) of data for each store\n",
        "last_week_per_store = df.groupby('Store')['Date'].max().reset_index()\n",
        "\n",
        "# Merge the last week information back to the original DataFrame to filter the last week's records for each store\n",
        "last_week_df = pd.merge(df, last_week_per_store, on=['Store', 'Date'], how='inner')\n",
        "\n",
        "# Display the result\n",
        "print(last_week_df)"
      ],
      "metadata": {
        "id": "myhLtwwXvaxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function predict_next_weeks_with_continuous_dates takes a DataFrame df, a prediction model, and the number of weeks to make the sales prediction for each store over the next 4 weeks.The Predicted Sales column is formatted to make the numbers easier to read by adding commas and rounding to 2 decimal places. Finally, it prints the first 50 rows of the predicted data."
      ],
      "metadata": {
        "id": "LGPE4Z4tyAs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "# Ensure 'Date' column is in datetime format before performing operations\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "# Check if any NaT values were introduced (if any date parsing failed)\n",
        "if df['Date'].isnull().sum() > 0:\n",
        "    print(\"Warning: Some dates could not be parsed and have been set to NaT. Check your data!\")\n",
        "\n",
        "# Function to predict for the next 4 weeks for 45 stores without modifying the original df\n",
        "def predict_next_weeks_with_continuous_dates(df, model, n_weeks=4):\n",
        "    df_copy = df.copy()  # Create a copy of df for prediction to prevent data modification\n",
        "    predictions = []  # List to store predictions for all stores over 4 weeks\n",
        "\n",
        "    for week in range(n_weeks):\n",
        "        weekly_predictions = []\n",
        "\n",
        "        for store in df_copy['Store'].unique():\n",
        "            # Filter data for the current store\n",
        "            store_data = df_copy[df_copy['Store'] == store]\n",
        "\n",
        "            # Prepare input features\n",
        "            X = store_data[['Store', 'Day', 'Month', 'Fuel_Price', 'CPI', 'Lagged_Sales', 'Temperature', 'Unemployment', 'Holiday_Flag']]\n",
        "\n",
        "            # Make the prediction for the current store\n",
        "            prediction = model.predict(X)[0]\n",
        "\n",
        "            # Store the date for the current store\n",
        "            current_date = pd.to_datetime(df_copy.loc[df_copy['Store'] == store, 'Date'].values[0])\n",
        "\n",
        "            weekly_predictions.append({\n",
        "                'Store': store,\n",
        "                'Date': current_date + timedelta(days=7),  # Add 7 days for each subsequent week\n",
        "                'Predicted Sales': prediction\n",
        "            })\n",
        "\n",
        "            # Update Lagged_Sales in df_copy for the next prediction round\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Lagged_Sales'] = prediction\n",
        "\n",
        "            # Update the day and month for the next week based on updated Date\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Date'] += timedelta(days=7)\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Day'] = df_copy['Date'].dt.day\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Month'] = df_copy['Date'].dt.month\n",
        "\n",
        "        # Append the week's predictions to the main list\n",
        "        predictions.extend(weekly_predictions)\n",
        "\n",
        "    return pd.DataFrame(predictions)\n",
        "\n",
        "# Call the function to predict for the next 4 weeks for all 45 stores\n",
        "predictions_df = predict_next_weeks_with_continuous_dates(last_week_df, xgbr, n_weeks=4)\n",
        "\n",
        "# Format 'Predicted Sales' for better readability\n",
        "predictions_df['Predicted Sales'] = predictions_df['Predicted Sales'].apply(lambda x: f\"{x:,.2f}\")\n",
        "\n",
        "# Display the final prediction DataFrame\n",
        "print(predictions_df.head(50))\n"
      ],
      "metadata": {
        "id": "MAANnKcl2vrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Predicted Sales' to a numeric format, removing commas\n",
        "predictions_df['Predicted Sales'] = predictions_df['Predicted Sales'].replace({',': ''}, regex=True).astype(float)\n",
        "# Convert the date strings to datetime objects first\n",
        "target_dates = pd.to_datetime(['2012-11-02', '2012-11-23'])\n",
        "\n",
        "\n",
        "# Filter data to include only the first 5 stores\n",
        "df_first_5 = predictions_df[\n",
        "    (predictions_df['Store'] <= 5) &\n",
        "    (predictions_df['Date'].isin(target_dates))\n",
        "][['Store', 'Date', 'Predicted Sales']]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot each store's predictions as a line\n",
        "for store in df_first_5['Store'].unique():\n",
        "    # Filter data for the current store\n",
        "    store_data = df_first_5[df_first_5['Store'] == store]\n",
        "\n",
        "    # Plot with date on x-axis and sales on y-axis\n",
        "    plt.plot(store_data['Date'], store_data['Predicted Sales'] / 1e6, label=f'Store {store}', marker='o')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Predicted Sales for First 5 Stores (2012-11-02 and 2012-11-23)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Predicted Sales (in Millions $)')\n",
        "\n",
        "# Format the y-axis to show commas and adjust to millions\n",
        "plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:,.1f}M'))\n",
        "\n",
        "# Display legend and plot\n",
        "plt.legend(title='Store')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GA-hIoeor703"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "# Ensure 'Date' column is in datetime format before performing operations\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "# Check if any NaT values were introduced (if any date parsing failed)\n",
        "if df['Date'].isnull().sum() > 0:\n",
        "    print(\"Warning: Some dates could not be parsed and have been set to NaT. Check your data!\")\n",
        "\n",
        "# Function to predict for the next 4 weeks for 45 stores without modifying the original df\n",
        "def predict_next_weeks_with_continuous_dates(df, model, n_weeks=4):\n",
        "    df_copy = df.copy()  # Create a copy of df for prediction to prevent data modification\n",
        "    predictions = []  # List to store predictions for all stores over 4 weeks\n",
        "\n",
        "    for week in range(n_weeks):\n",
        "        weekly_predictions = []\n",
        "\n",
        "        for store in df_copy['Store'].unique():\n",
        "            # Filter data for the current store\n",
        "            store_data = df_copy[df_copy['Store'] == store]\n",
        "\n",
        "            # Prepare input features\n",
        "            X = store_data[['Store', 'Day', 'Month', 'Fuel_Price', 'CPI', 'Lagged_Sales', 'Temperature', 'Unemployment', 'Holiday_Flag']]\n",
        "\n",
        "            # Make the prediction for the current store\n",
        "            prediction = model.predict(X)[0]\n",
        "\n",
        "            # Store the date for the current store\n",
        "            current_date = pd.to_datetime(df_copy.loc[df_copy['Store'] == store, 'Date'].values[0])\n",
        "\n",
        "            weekly_predictions.append({\n",
        "                'Store': store,\n",
        "                'Date': current_date + timedelta(days=7),  # Add 7 days for each subsequent week\n",
        "                'Predicted Sales': prediction\n",
        "            })\n",
        "\n",
        "            # Update Lagged_Sales in df_copy for the next prediction round\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Lagged_Sales'] = prediction\n",
        "\n",
        "            # Update the day and month for the next week based on updated Date\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Date'] += timedelta(days=7)\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Day'] = df_copy['Date'].dt.day\n",
        "            df_copy.loc[df_copy['Store'] == store, 'Month'] = df_copy['Date'].dt.month\n",
        "\n",
        "        # Append the week's predictions to the main list\n",
        "        predictions.extend(weekly_predictions)\n",
        "\n",
        "    return pd.DataFrame(predictions)\n",
        "\n",
        "# Call the function to predict for the next 12 weeks for all 45 stores\n",
        "predictions_df = predict_next_weeks_with_continuous_dates(last_week_df, xgbr, n_weeks=12) #Changed the number of Weeks from 4 to 12)\n",
        "\n",
        "# Format 'Predicted Sales' for better readability\n",
        "predictions_df['Predicted Sales'] = predictions_df['Predicted Sales'].apply(lambda x: f\"{x:,.2f}\")\n",
        "\n",
        "# Display the final prediction DataFrame\n",
        "print(predictions_df.head(540))\n"
      ],
      "metadata": {
        "id": "-76zYox4QRy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Predicted Sales' to a numeric format, removing commas\n",
        "predictions_df['Predicted Sales'] = predictions_df['Predicted Sales'].replace({',': ''}, regex=True).astype(float)\n",
        "# Convert the date strings to datetime objects first\n",
        "target_dates = pd.to_datetime(['2012-11-02', '2013-01-18']) # Changed from 2012-23-11 to 2013-01-18\n",
        "\n",
        "\n",
        "# Filter data to include only the first 5 stores\n",
        "df_first_5 = predictions_df[\n",
        "    (predictions_df['Store'] <= 5) &\n",
        "    (predictions_df['Date'].isin(target_dates))\n",
        "][['Store', 'Date', 'Predicted Sales']]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot each store's predictions as a line\n",
        "for store in df_first_5['Store'].unique():\n",
        "    # Filter data for the current store\n",
        "    store_data = df_first_5[df_first_5['Store'] == store]\n",
        "\n",
        "    # Plot with date on x-axis and sales on y-axis\n",
        "    plt.plot(store_data['Date'], store_data['Predicted Sales'] / 1e6, label=f'Store {store}', marker='o')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Predicted Sales for First 5 Stores (2012-11-02 and 2013-01-18)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Predicted Sales (in Millions $)')\n",
        "\n",
        "# Format the y-axis to show commas and adjust to millions\n",
        "plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:,.1f}M'))\n",
        "\n",
        "# Display legend and plot\n",
        "plt.legend(title='Store')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9y2FQ5_BQ_ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}